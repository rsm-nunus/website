[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nujoum Unus",
    "section": "",
    "text": "Nujoum Unus is pursuing her Masters in Business Analytics at the University of California, San Diego. A dedicated data science student with a passion for harnessing the power of machine learning, NLP, and generative AI to solve real-world business challenges; she excels in transforming complex datasets into strategic insights that drive decision-making and efficiency."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Nujoum Unus",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA MS Business Analytics | Aug 2024 - Dec 2025\nA.P.J. Abdul Kalam Technological University | Kerala, India B.Tech in Computer Science and Engineering | July 2019 - June 2023"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Nujoum Unus",
    "section": "Experience",
    "text": "Experience\nBriteCap Financial | Data Science Capstone | April 2025 - present\nTriton Power | Marketing Analyst Fellowship | April 2025 - present\nAutomation Engineer | TATA ELXSI | Nov 2023 - May 2024"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "WELCOME Y’ALL"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\n Background \nCharitable organizations often rely on fundraising letters to solicit donations, but little rigorous evidence has been available to guide how those letters should be designed. In a groundbreaking field experiment, economists Dean Karlan and John List set out to test how different framing strategies and financial incentives affect individual donation behavior.\nThe experiment, conducted in collaboration with a politically-oriented nonprofit organization, involved mailing 50,083 fundraising letters to previous donors. Crucially, the recipients were randomly assigned to different treatment groups, allowing the researchers to measure causal effects rather than mere correlations.\n Purpose of the Study \nKarlan and List aimed to answer a simple but important question:\n&gt; Do people give more when their donation is matched? And if so, does the size of the match matter?\nThey also explored additional behavioral levers commonly used in fundraising, such as challenge framing, suggested donation amounts, and goal-based appeals.\n Experimental Design \nThe letters fell into three broad treatment types:\n\nStandard Fundraising Letter (Control)\n\nA typical letter requesting support for the organization, with no additional incentives or matching language.\n\nMatching Grant Letter\n\nIncluded a paragraph stating that a leadership donor would match any contribution at one of three possible ratios:\n\n1:1 (every dollar given is doubled)\n\n2:1 (every dollar is tripled)\n\n3:1 (every dollar quadrupled)\n\n\nMatching offers also varied by threshold, i.e., the maximum amount the leadership donor would match:\n\n$25,000, $50,000, $100,000, or unstated.\n\nSuggested donation levels were tailored based on each recipient’s previous giving history:\n\nTheir highest previous gift\n\n1.25× their highest gift\n\n1.5× their highest gift\n\n\nChallenge Grant Letter\n\nFramed the offer as part of a collective effort or campaign challenge, appealing to urgency and social impact rather than pure match mechanics.\n\n\nBecause each component (match ratio, threshold, suggested donation amount) was randomized independently within the matching grant group, the experiment had a factorial design — allowing the researchers to isolate and measure the effects of each variable.\n Why This Matters \nAt the time of the study, fundraisers often relied on rules of thumb and anecdotes, lacking hard data on what actually drives giving. Karlan and List’s approach brought scientific rigor to the domain of nonprofit fundraising by:\n\nLeveraging random assignment to establish causality\nTesting commonly used marketing strategies under real-world conditions\nGenerating insights with practical implications for organizations seeking to raise more money\n\n Contribution to the Literature \nThis study represents one of the first large-scale natural field experiments in charitable giving. It moved beyond lab settings and survey experiments to observe real decisions involving real money. The results helped bridge the gap between behavioral economics and fundraising practice, offering evidence-backed recommendations on:\n\nThe efficacy of matching offers\n\nHow much match ratios influence behavior\n\nWhether people respond to thresholds or suggested amounts\n\nThe heterogeneous effects by donor characteristics and geography\n\n Project Overview \nIn this replication study, we use the same dataset provided by Karlan and List to:\n\nReproduce their key findings\nValidate the statistical robustness of their claims\nExplore new visualizations and simulations that illuminate the behavioral mechanisms at play\nReflect on what this experiment teaches us about human motivation, social framing, and economic incentives in the context of public goods\n\nThis report follows a structured analysis of donation likelihood, donation size, and how different dimensions of the match offer (ratio, threshold, framing) influence both."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\n Background \nCharitable organizations often rely on fundraising letters to solicit donations, but little rigorous evidence has been available to guide how those letters should be designed. In a groundbreaking field experiment, economists Dean Karlan and John List set out to test how different framing strategies and financial incentives affect individual donation behavior.\nThe experiment, conducted in collaboration with a politically-oriented nonprofit organization, involved mailing 50,083 fundraising letters to previous donors. Crucially, the recipients were randomly assigned to different treatment groups, allowing the researchers to measure causal effects rather than mere correlations.\n Purpose of the Study \nKarlan and List aimed to answer a simple but important question:\n&gt; Do people give more when their donation is matched? And if so, does the size of the match matter?\nThey also explored additional behavioral levers commonly used in fundraising, such as challenge framing, suggested donation amounts, and goal-based appeals.\n Experimental Design \nThe letters fell into three broad treatment types:\n\nStandard Fundraising Letter (Control)\n\nA typical letter requesting support for the organization, with no additional incentives or matching language.\n\nMatching Grant Letter\n\nIncluded a paragraph stating that a leadership donor would match any contribution at one of three possible ratios:\n\n1:1 (every dollar given is doubled)\n\n2:1 (every dollar is tripled)\n\n3:1 (every dollar quadrupled)\n\n\nMatching offers also varied by threshold, i.e., the maximum amount the leadership donor would match:\n\n$25,000, $50,000, $100,000, or unstated.\n\nSuggested donation levels were tailored based on each recipient’s previous giving history:\n\nTheir highest previous gift\n\n1.25× their highest gift\n\n1.5× their highest gift\n\n\nChallenge Grant Letter\n\nFramed the offer as part of a collective effort or campaign challenge, appealing to urgency and social impact rather than pure match mechanics.\n\n\nBecause each component (match ratio, threshold, suggested donation amount) was randomized independently within the matching grant group, the experiment had a factorial design — allowing the researchers to isolate and measure the effects of each variable.\n Why This Matters \nAt the time of the study, fundraisers often relied on rules of thumb and anecdotes, lacking hard data on what actually drives giving. Karlan and List’s approach brought scientific rigor to the domain of nonprofit fundraising by:\n\nLeveraging random assignment to establish causality\nTesting commonly used marketing strategies under real-world conditions\nGenerating insights with practical implications for organizations seeking to raise more money\n\n Contribution to the Literature \nThis study represents one of the first large-scale natural field experiments in charitable giving. It moved beyond lab settings and survey experiments to observe real decisions involving real money. The results helped bridge the gap between behavioral economics and fundraising practice, offering evidence-backed recommendations on:\n\nThe efficacy of matching offers\n\nHow much match ratios influence behavior\n\nWhether people respond to thresholds or suggested amounts\n\nThe heterogeneous effects by donor characteristics and geography\n\n Project Overview \nIn this replication study, we use the same dataset provided by Karlan and List to:\n\nReproduce their key findings\nValidate the statistical robustness of their claims\nExplore new visualizations and simulations that illuminate the behavioral mechanisms at play\nReflect on what this experiment teaches us about human motivation, social framing, and economic incentives in the context of public goods\n\nThis report follows a structured analysis of donation likelihood, donation size, and how different dimensions of the match offer (ratio, threshold, framing) influence both."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\nimport pandas as pd\ndf = pd.read_stata('karlan_list_2007.dta')\ndf.info()\ndf.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\nWe tested whether the treatment and control groups differed in prior donor behavior by comparing the number of months since last donation (mrm2). Both a two-sample t-test (t = 0.120, p = 0.905) and a linear regression of mrm2 ~ treatment (β = 0.0137, p = 0.905) confirm no statistically significant difference. This supports the randomization mechanism and matches Table 1 in Karlan and List (2007).\n\nfrom scipy import stats\n\n# Clean data: drop NAs\ndf_clean = df[[\"mrm2\", \"treatment\", \"control\"]].dropna()\n\n# Split groups\ntreat = df_clean[df_clean['treatment'] == 1]['mrm2']\ncontrol = df_clean[df_clean['control'] == 1]['mrm2']\n\n# Perform Welch's t-test (no assumption of equal variances)\nttest = stats.ttest_ind(treat, control, equal_var=False)\n\n# Print results\nprint(f\"T-test result: t = {ttest.statistic:.3f}, p = {ttest.pvalue:.3f}\")\n\nimport statsmodels.formula.api as smf\n\n# Regression of mrm2 on treatment\nmodel = smf.ols(\"mrm2 ~ treatment\", data=df_clean).fit()\nmodel.summary()\n\nT-test result: t = 0.120, p = 0.905\n\n\n\nOLS Regression Results\n\n\nDep. Variable:\nmrm2\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.01428\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.905\n\n\nTime:\n22:29:36\nLog-Likelihood:\n-1.9585e+05\n\n\nNo. Observations:\n50082\nAIC:\n3.917e+05\n\n\nDf Residuals:\n50080\nBIC:\n3.917e+05\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n12.9981\n0.094\n138.979\n0.000\n12.815\n13.181\n\n\ntreatment\n0.0137\n0.115\n0.119\n0.905\n-0.211\n0.238\n\n\n\n\n\n\n\n\nOmnibus:\n8031.352\nDurbin-Watson:\n2.004\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n12471.135\n\n\nSkew:\n1.163\nProb(JB):\n0.00\n\n\nKurtosis:\n3.751\nCond. No.\n3.23\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n Interpretation \nWe assess balance between treatment and control groups using both statistical methods:\n\nT-Test:\n\nt = 0.120, p = 0.905\n\nResult: Not statistically significant\n\nRegression:\n\nCoefficient on treatment ≈ 0.014\n\np-value ≈ 0.905\n\n95% Confidence Interval: Includes zero\n\n\nThese results confirm no significant difference in mrm2 across groups, supporting the randomization mechanism. This aligns with Table 1 in Karlan & List (2007), where the group means were:\n\n\n\nGroup\nMean Months Since Last Donation\n\n\n\n\nTreatment\n13.012\n\n\nControl\n12.998"
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\n\nimport matplotlib.pyplot as plt\ngave_by_group = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ngave_by_group[\"group\"] = gave_by_group[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\nplt.figure(figsize=(6, 4))\nplt.bar(gave_by_group[\"group\"], gave_by_group[\"gave\"], width=0.5)\nplt.title(\"Proportion Who Donated by Group\")\nplt.ylabel(\"Proportion Gave\")\nplt.ylim(0, gave_by_group[\"gave\"].max() + 0.01)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWe compare the response rate (i.e., whether a donation was made) between treatment and control groups.\nThe bar plot below shows that the treatment group, who received a matching grant offer, donated at a higher rate than the control group, who received a standard letter.\nThis visual confirms the core finding in Karlan & List (2007): matching donations increased participation in charitable giving.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Ensure binary outcome is correctly typed\ndf['gave'] = df['gave'].astype(int)\n\n# T-test: response rate (gave) between treatment and control groups\ngave_treat = df[df['treatment'] == 1]['gave']\ngave_control = df[df['control'] == 1]['gave']\nt_stat, p_val = ttest_ind(gave_treat, gave_control, equal_var=False)\n\n# Regression: response as a function of treatment\nreg_gave = smf.ols('gave ~ treatment', data=df).fit()\n\nt_stat, p_val, reg_gave.summary()\n\n(3.2094621908279835,\n 0.0013309823450914173,\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\n Time:                        22:29:36   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n Charitable Contribution Made \nWe examine whether receiving a matching donation offer increases the likelihood of making a charitable donation. This is measured using the binary variable gave, which equals 1 if a donation was made and 0 otherwise.\nWe use both a t-test and a bivariate linear regression to assess the difference in response rate between treatment and control groups.\n Results Summary \n\n\n\n\n\n\n\n\n\nMethod\nEffect Size\np-value\nInterpretation\n\n\n\n\nT-Test\nt = 3.21\n0.0013\nStatistically significant\n\n\nRegression\n+0.0042 (0.42%)\n0.002\nStatistically significant\n\n\n\n\nControl group donation rate ≈ 1.79%\n\nTreatment group donation rate ≈ 2.21%\n\nThese values match the response rates reported in Table 2A, Panel A of Karlan & List (2007).\n Table 2A (Panel A): Response Rate Comparison \n\n\n\nGroup\nResponse Rate\nStd. Error\n\n\n\n\nControl\n0.018\n(0.001)\n\n\nTreatment\n0.022\n(0.001)\n\n\nMatch 1:1\n0.021\n(0.001)\n\n\nMatch 2:1\n0.023\n(0.001)\n\n\nMatch 3:1\n0.023\n(0.001)\n\n\n\n\nSource: Karlan & List (2007), Table 2A, Panel A\n\n Interpretation \nEven a small increase in the likelihood of giving — about 0.4 percentage points — is statistically significant in a large-scale field experiment with over 50,000 individuals.\nThis result shows that: - Matching donations have a causal impact on behavior. - People are more likely to respond to donation appeals when told their gift will be matched. - The psychological effect (e.g., feeling of leverage, social validation, urgency) may be as important as the financial incentive.\nThus, matched donations are an effective strategy not just in economics but in behavioral design for charitable fundraising.\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\nimport statsmodels.api as sm\n\n# Prepare the variables\nX = sm.add_constant(df[\"treatment\"])\ny = df[\"gave\"]\n\n# Run the Probit regression\nprobit_model = sm.Probit(y, X)\nprobit_results = probit_model.fit()\n\nprobit_results.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nProbit\nDf Residuals:\n50081\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nWed, 23 Apr 2025\nPseudo R-squ.:\n0.0009783\n\n\nTime:\n22:29:37\nLog-Likelihood:\n-5030.5\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.001696\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-2.1001\n0.023\n-90.073\n0.000\n-2.146\n-2.054\n\n\ntreatment\n0.0868\n0.028\n3.113\n0.002\n0.032\n0.141\n\n\n\n\n\n Probit Regression: Impact of Matching Grant on Donation Likelihood \nTo replicate Table 3, Column (1) from Karlan & List (2007), we estimate a Probit model where the outcome is whether a donation was made (gave = 1) and the explanatory variable is assignment to treatment (treatment = 1).\n Our Probit Model Results \n\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\nz-value\np-value\n95% CI\n\n\n\n\nIntercept\n-2.100\n0.023\n-90.07\n&lt; 0.001\n[-2.146, -2.054]\n\n\nTreatment\n0.087\n0.028\n3.11\n0.002\n[0.032, 0.141]\n\n\n\n\nPseudo R²: 0.001\n\nObservations: 50,083\n\nThese results match the direction and significance of Table 3, Column (1) in the original study.\n Table 3: Primary Probit Regression Results from Karlan & List (2007) \n\n\n\n\n\n\n\n\n\nVariable\n(1) All\nStd. Err.\nSignificance\n\n\n\n\nTreatment\n0.004\n(0.001)\n***\n\n\nTreatment × 2:1 ratio\n0.002\n(0.002)\n\n\n\nTreatment × 3:1 ratio\n0.002\n(0.002)\n\n\n\nTreatment × $25,000 threshold\n-0.001\n(0.002)\n\n\n\nTreatment × $50,000 threshold\n0.000\n(0.002)\n\n\n\nTreatment × $100,000 threshold\n-0.000\n(0.002)\n\n\n\nTreatment × medium example amount\n0.001\n(0.002)\n\n\n\nTreatment × high example amount\n0.001\n(0.002)\n\n\n\nPseudo R²\n0.001\n\n\n\n\nObservations\n50,083\n\n\n\n\n\nNotes: - The paper reports marginal effects, whereas our Probit output gives latent index coefficients. - The magnitude of 0.004 in the paper corresponds to a marginal increase in probability of donating due to the treatment. - Our coefficient of 0.087 reflects the effect on the underlying propensity to give, which is standard in Probit estimation.\n Interpretation \nDespite a small effect size, the impact of being offered a matching donation is statistically significant. This suggests:\n\nEven subtle nudges, like framing a gift as matched by a leadership donor, can increase participation.\nThe result is economically meaningful due to the large sample size and real-world behavioral context.\n\nIn short: human generosity is sensitive to framing — and donors are more likely to act when they feel their gift has leverage.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\n# Subset the data for different match ratios\n# According to the dataset: ratio = '1', '2', '3' for 1:1, 2:1, 3:1\ndf_ratio = df[df[\"treatment\"] == 1].copy()\ndf_ratio[\"ratio\"] = df_ratio[\"ratio\"].astype(str)\n\n# Extract binary 'gave' for each match ratio group\ngave_1_1 = df_ratio[df_ratio[\"ratio\"] == \"1\"][\"gave\"]\ngave_2_1 = df_ratio[df_ratio[\"ratio\"] == \"2\"][\"gave\"]\ngave_3_1 = df_ratio[df_ratio[\"ratio\"] == \"3\"][\"gave\"]\n\n# Perform t-tests between match ratio groups\nttest_1_vs_2 = ttest_ind(gave_1_1, gave_2_1, equal_var=False)\nttest_1_vs_3 = ttest_ind(gave_1_1, gave_3_1, equal_var=False)\nttest_2_vs_3 = ttest_ind(gave_2_1, gave_3_1, equal_var=False)\n\nttest_1_vs_2, ttest_1_vs_3, ttest_2_vs_3\n\n(TtestResult(statistic=-0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836),\n TtestResult(statistic=-1.0150174470156275, pvalue=0.31010856527625774, df=22215.0529778684),\n TtestResult(statistic=-0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778))\n\n\n Does Match Ratio Size Affect Donation Rates? \nWe investigate whether increasing the match ratio (from 1:1 to 2:1 to 3:1) has a statistically significant effect on the likelihood that someone donates.\nTo do this, we run a series of t-tests comparing donation rates (gave = 1) across match ratio groups, restricting the sample to individuals who received a matching offer.\n\n T-Test Results by Match Ratio \n\n\n\n\n\n\n\n\n\nComparison\nt-statistic\np-value\nInterpretation\n\n\n\n\n1:1 vs 2:1 match\n-0.965\n0.335\n❌ Not statistically significant\n\n\n1:1 vs 3:1 match\n-1.015\n0.310\n❌ Not statistically significant\n\n\n2:1 vs 3:1 match\n-0.050\n0.960\n❌ Not statistically significant\n\n\n\n Interpretation \nThese results show no significant difference in donation rates across the different match ratios. This means that:\n\nIncreasing the match multiplier from 1:1 to 2:1 or 3:1 does not lead to a higher likelihood of giving.\nThis supports the statement from Karlan & List (2007, p. 8):\n\n\n“The gift distributions across the various matching ratios are not significantly different from one another.”\n\nIn other words, people respond positively to the existence of a match, but not necessarily more when the match becomes more generous.\n Conclusion \nThe presence of a match appears to matter more than its magnitude. This suggests that:\n\nFraming and social cues — like simply saying “your gift will be matched” — may be more behaviorally powerful than the precise financial terms.\n\nThis insight is important for nonprofit fundraisers: focus on highlighting the match rather than inflating the ratio.\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\n\n# Ensure 'gave' is binary\ndf['gave'] = df['gave'].astype(int)\n\n# Create dummy variables for each match ratio\n# This is only for treatment group, so filter and prepare accordingly\ndf_ratio = df[df['treatment'] == 1].copy()\ndf_ratio['ratio'] = df_ratio['ratio'].astype(str)\n\n# Create dummy variables: ratio1, ratio2, ratio3\ndf_ratio['ratio1'] = (df_ratio['ratio'] == '1').astype(int)\ndf_ratio['ratio2'] = (df_ratio['ratio'] == '2').astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == '3').astype(int)\n\n# Regression: gave ~ ratio1 + ratio2 + ratio3 (no intercept)\nimport statsmodels.api as sm\n\nX = df_ratio[['ratio1', 'ratio2', 'ratio3']]\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\n\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.6454\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.524\n\n\nTime:\n22:29:37\nLog-Likelihood:\n16688.\n\n\nNo. Observations:\n33396\nAIC:\n-3.337e+04\n\n\nDf Residuals:\n33393\nBIC:\n-3.334e+04\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nratio1\n0.0207\n0.001\n14.912\n0.000\n0.018\n0.023\n\n\nratio2\n0.0226\n0.001\n16.267\n0.000\n0.020\n0.025\n\n\nratio3\n0.0227\n0.001\n16.335\n0.000\n0.020\n0.025\n\n\n\n\n\n\n\n\nOmnibus:\n38963.957\nDurbin-Watson:\n1.995\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n2506478.937\n\n\nSkew:\n6.511\nProb(JB):\n0.00\n\n\nKurtosis:\n43.394\nCond. No.\n1.00\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n Behavioral Insight: Why Match Size Doesn’t Matter (Much) \nThis regression shows that all forms of match ratios — 1:1, 2:1, and 3:1 — significantly increase the likelihood that someone donates, with donation rates clustering around 2%.\nHowever, the differences between match sizes are extremely small:\n\nPeople who saw a 1:1 match donated at a rate of 2.07%.\nThose who saw a 2:1 match gave at 2.26%.\nWith a 3:1 match, the rate was 2.27%.\n\nThese results suggest that once a match is present, increasing its generosity has little additional impact. In other words:\n\nIt’s the existence of the match that matters, not its size.\n\nThis behavior aligns with theories in behavioral economics: - The match acts as a signal of social proof or endorsement. - It may create a sense of urgency or leverage (“my donation matters more”). - But donors aren’t particularly sensitive to how generous the match is — at least not in terms of deciding whether or not to give.\n Implication for Fundraising \nFrom a practical standpoint, this means that: - Fundraisers don’t need to offer high match ratios to see results. - A simple, clearly communicated 1:1 match may be just as effective as a 3:1 match in increasing participation.\nThis finding reinforces the power of framing and perception in influencing human behavior.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n# Compute the actual mean response (gave) for each ratio group directly from the data\nmean_1_1 = df_ratio[df_ratio[\"ratio\"] == \"1\"][\"gave\"].mean()\nmean_2_1 = df_ratio[df_ratio[\"ratio\"] == \"2\"][\"gave\"].mean()\nmean_3_1 = df_ratio[df_ratio[\"ratio\"] == \"3\"][\"gave\"].mean()\n\n# Calculate differences in response rates\ndiff_2_1_vs_1_1 = mean_2_1 - mean_1_1\ndiff_3_1_vs_2_1 = mean_3_1 - mean_2_1\n\n# Extract coefficients from regression model\ncoef_1_1 = model.params[\"ratio1\"]\ncoef_2_1 = model.params[\"ratio2\"]\ncoef_3_1 = model.params[\"ratio3\"]\n\n# Calculate differences in coefficients\ncoef_diff_2_1_vs_1_1 = coef_2_1 - coef_1_1\ncoef_diff_3_1_vs_2_1 = coef_3_1 - coef_2_1\n\n(mean_1_1, mean_2_1, mean_3_1,\n diff_2_1_vs_1_1, diff_3_1_vs_2_1,\n coef_diff_2_1_vs_1_1, coef_diff_3_1_vs_2_1)\n\n(0.020749124225276205,\n 0.0226333752469912,\n 0.022733399227244138,\n 0.0018842510217149944,\n 0.00010002398025293902,\n 0.0018842510217149805,\n 0.00010002398025296677)\n\n\n Comparing Response Rates Across Match Ratios \nWe examine how the size of the match (1:1 vs. 2:1 vs. 3:1) influences the probability that an individual makes a donation. We do this in two ways:\n\nDirectly from the data by calculating average donation rates within each match group.\nFrom the fitted coefficients of a regression on dummy variables for each ratio.\n\n\n Response Rate Differences \n\n\n\n\n\n\n\n\nComparison\nDirect from Data\nFrom Regression Coefficients\n\n\n\n\n2:1 vs 1:1 match\n0.00188 (0.19%)\n0.00188 (0.19%)\n\n\n3:1 vs 2:1 match\n0.00010 (0.01%)\n0.00010 (0.01%)\n\n\n\n\nThese differences represent increases in the probability of donating when moving from one match ratio to a higher one.\nThe results are identical across both methods, which supports the robustness of the findings.\n\n Interpretation \n\nMoving from a 1:1 to 2:1 match slightly increases donation rates by about 0.19 percentage points.\nIncreasing from a 2:1 to a 3:1 match has a negligible effect — only 0.01 percentage points.\nThese differences are statistically very small and are unlikely to be meaningful in practice.\n\n Conclusion \nOur analysis shows that:\n\nOnce a match is introduced, increasing the match ratio does not meaningfully increase the likelihood of giving.\n\nThis confirms the finding from Karlan & List (2007):\n\n“The gift distributions across the various matching ratios are not significantly different from one another.”\n\nIn short, it’s the presence of a match offer — not its generosity — that influences donor behavior.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\n\n# Run a t-test on the amount given between treatment and control groups\namount_treat = df[df['treatment'] == 1]['amount']\namount_control = df[df['control'] == 1]['amount']\namount_ttest = ttest_ind(amount_treat, amount_control, equal_var=False)\n\n# Run a bivariate linear regression: amount ~ treatment\namount_reg = smf.ols('amount ~ treatment', data=df).fit()\n\namount_ttest.statistic, amount_ttest.pvalue, amount_reg.summary()\n\n(1.9182618934467577,\n 0.05508566528918335,\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     3.461\n Date:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\n Time:                        22:29:37   Log-Likelihood:            -1.7946e+05\n No. Observations:               50083   AIC:                         3.589e+05\n Df Residuals:                   50081   BIC:                         3.589e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.8133      0.067     12.063      0.000       0.681       0.945\n treatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n ==============================================================================\n Omnibus:                    96861.113   Durbin-Watson:                   2.008\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\n Skew:                          15.297   Prob(JB):                         0.00\n Kurtosis:                     341.269   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n Size of Charitable Contribution \nWe tested whether receiving a matching donation offer affects the amount donated using a t-test and linear regression:\n Results \n\n\n\n\n\n\n\n\n\nMethod\nTreatment Effect\np-value\nConclusion\n\n\n\n\nT-Test\n+$0.15\n0.055\n🔸 Marginally not significant\n\n\nRegression\n+$0.15\n0.063\n🔸 Suggestive but inconclusive\n\n\n\n\nControl group average: ~$0.81\n\nTreatment group average: ~$0.96\n\n Interpretation \n\nThe treatment group gave slightly more, but the difference is not statistically significant at the 5% level.\nThis suggests that while match offers increase participation, they have a much smaller effect on how much people give.\n\n Takeaway \n\nMatching donations may encourage more people to give, but do not substantially increase donation size.\n\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\n\n# Limit the data to only those who made a donation (amount &gt; 0)\ndf_positive = df[df['amount'] &gt; 0].copy()\n\n# T-test for amount among donors only\namount_treat_pos = df_positive[df_positive['treatment'] == 1]['amount']\namount_control_pos = df_positive[df_positive['control'] == 1]['amount']\namount_ttest_pos = ttest_ind(amount_treat_pos, amount_control_pos, equal_var=False)\n\n# Regression: amount ~ treatment (for donors only)\namount_reg_pos = smf.ols('amount ~ treatment', data=df_positive).fit()\n\namount_ttest_pos.statistic, amount_ttest_pos.pvalue, amount_reg_pos.summary()\n\n(-0.5846089794983359,\n 0.5590471865673547,\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                 amount   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                 -0.001\n Method:                 Least Squares   F-statistic:                    0.3374\n Date:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\n Time:                        22:29:37   Log-Likelihood:                -5326.8\n No. Observations:                1034   AIC:                         1.066e+04\n Df Residuals:                    1032   BIC:                         1.067e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept     45.5403      2.423     18.792      0.000      40.785      50.296\n treatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n ==============================================================================\n Omnibus:                      587.258   Durbin-Watson:                   2.031\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\n Skew:                           2.464   Prob(JB):                         0.00\n Kurtosis:                      13.307   Cond. No.                         3.49\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n Conditional Donation Amount: Among Donors Only \nTo isolate the effect of treatment on the amount given, we restrict the sample to only those individuals who made a donation (amount &gt; 0).\nWe use both a t-test and a bivariate regression (amount ~ treatment) to compare average donation sizes between treatment and control groups.\n Results Summary \n\n\n\n\n\n\n\n\n\nMethod\nTreatment Effect\np-value\nConclusion\n\n\n\n\nT-Test (donors only)\nt = -0.58\n0.559\n❌ Not statistically significant\n\n\nRegression\n-$1.67\n0.561\n❌ Not statistically significant\n\n\n\n\nControl group average donation: ~$45.54\n\nTreatment group average donation: ~$43.87\n\n Interpretation \n\nThe treatment group donated slightly less on average, but the difference is not statistically meaningful.\nThis suggests that while the match offer encourages more people to donate, it does not increase donation size among those who would give anyway.\nBecause we only include those who donated, the treatment effect here is not causal — it’s conditional and may suffer from selection bias.\n\n Conclusion \n\nMatched donations are effective at increasing the number of donors, but not the amount donated by each donor — at least among those who already choose to give.\n\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\nimport matplotlib.pyplot as plt\n\n# Filter to donors only\ndf_donors = df[df[\"amount\"] &gt; 0]\n\n# Separate treatment and control donors\ntreat_donors = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\ncontrol_donors = df_donors[df_donors[\"control\"] == 1][\"amount\"]\n\n# Calculate means\nmean_treat = treat_donors.mean()\nmean_control = control_donors.mean()\n\n# Create side-by-side histograms\nfig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\n# Control group plot\naxes[0].hist(control_donors, bins=30, color=\"skyblue\", edgecolor=\"black\")\naxes[0].axvline(mean_control, color=\"red\", linestyle=\"--\", label=f\"Mean = ${mean_control:.2f}\")\naxes[0].set_title(\"Control Group Donations\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].legend()\n\n# Treatment group plot\naxes[1].hist(treat_donors, bins=30, color=\"lightgreen\", edgecolor=\"black\")\naxes[1].axvline(mean_treat, color=\"red\", linestyle=\"--\", label=f\"Mean = ${mean_treat:.2f}\")\naxes[1].set_title(\"Treatment Group Donations\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n Distribution of Donation Amounts Among Donors \nWe now focus on individuals who actually made a donation (amount &gt; 0) to analyze how much they gave, and whether the treatment group (those offered a matching donation) gave more than the control group.\nWe visualize the distribution of donation amounts with two histograms — one for each group — and include a red dashed line indicating the average donation in each.\n Interpretation \n\nBoth distributions are heavily right-skewed, which is common in charitable giving: most donors give modest amounts, but a few give significantly more.\nThe average donation in the control group was about $45.54, while the treatment group averaged $43.87.\nThis difference is not statistically significant, as confirmed by both a t-test and a regression limited to donors.\n\n What Did We Learn? \n\nWhile the matching donation offer increases the probability of donating, it does not increase the donation amount among those who choose to give.\nIn fact, the average donation in the treatment group is slightly lower, though the difference is not meaningful.\n\n Important Caveat \nThis analysis is based only on people who gave, so the treatment coefficient does not have a causal interpretation here. This subset is not randomly assigned — it’s a selected group, which may differ systematically between treatment and control.\n Fundraising Implication \n\nMatching offers are powerful tools to increase participation, but they do not necessarily lead to larger individual gifts.\n\nTo increase average donation size, fundraisers may need additional tactics — such as suggested donation levels, tiered match thresholds, or social proof."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Extract donation amounts for control and treatment\ncontrol_data = df[df[\"control\"] == 1][\"amount\"]\ntreatment_data = df[df[\"treatment\"] == 1][\"amount\"]\n\n# Simulate draws from each distribution\nnp.random.seed(42)\nsim_control = np.random.choice(control_data, size=100_000, replace=True)\nsim_treatment = np.random.choice(treatment_data, size=10_000, replace=True)\n\n# Calculate 10,000 differences between treatment and control draws\nsim_control_subset = np.random.choice(sim_control, size=10_000, replace=False)\ndiffs = sim_treatment - sim_control_subset\n\n# Compute cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Average Difference\")\nplt.axhline(y=np.mean(treatment_data) - np.mean(control_data), color=\"red\", linestyle=\"--\", label=\"True Mean Difference\")\nplt.title(\"Cumulative Average of Treatment-Control Differences\")\nplt.xlabel(\"Number of Draws\")\nplt.ylabel(\"Cumulative Average Difference in Donation Amount\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n Simulated Cumulative Average Differences \nTo better understand the behavior of sample averages and connect to the concepts from our first class (Slide 43), we simulate the cumulative effect of donation differences between the treatment and control groups.\n Simulation Setup \n\nWe simulate 100,000 random draws from the control group donation distribution.\nWe simulate 10,000 random draws from the treatment group.\nFor each of the 10,000 pairs, we calculate the difference: treatment - control.\nWe then compute the cumulative average of these 10,000 differences.\n\n Plot Interpretation \nThe plot below shows:\n\nA blue line representing the cumulative average of the simulated differences.\nA red dashed line indicating the true difference in means between treatment and control groups (calculated from the full dataset).\n\nAs the number of draws increases, the cumulative average approaches the true difference.\nThis illustrates the Law of Large Numbers: with enough data, sample-based estimates converge to the population value.\n What We Learnt \n\nThis simulation confirms that even in noisy, skewed data like donations, repeated sampling yields reliable estimates.\n\nIt also demonstrates that the difference in means we compute from data is not just a fluke — it’s what we’d expect if we sampled repeatedly from the same distributions.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\n# Define a function to simulate mean differences for a given sample size\ndef simulate_differences(sample_size, n_reps=1000):\n    differences = []\n    for _ in range(n_reps):\n        sample_control = np.random.choice(control_data, size=sample_size, replace=True)\n        sample_treatment = np.random.choice(treatment_data, size=sample_size, replace=True)\n        differences.append(np.mean(sample_treatment) - np.mean(sample_control))\n    return differences\n\n# Simulate for each sample size\nnp.random.seed(42)\nsizes = [50, 200, 500, 1000]\nsimulated_results = {size: simulate_differences(size) for size in sizes}\n\n# Plot histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, size in enumerate(sizes):\n    axes[i].hist(simulated_results[size], bins=30, color='lightgray', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='--', label=\"Zero\")\n    axes[i].set_title(f\"Sample Size = {size}\")\n    axes[i].set_xlabel(\"Mean Difference (Treatment - Control)\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n Sampling Distributions at Different Sample Sizes \nTo mirror the exercise from Slide 44 of our first class, we simulate the sampling distribution of the mean difference in donation amount between the treatment and control groups.\nFor each of four different sample sizes — 50, 200, 500, and 1000 — we:\n\nDraw n observations from each group.\nCompute the difference in mean donation: treatment - control.\nRepeat the process 1,000 times.\nPlot the histogram of those 1,000 average differences.\n\n Histograms of Simulated Mean Differences \nEach plot includes a red dashed line at zero, representing the null hypothesis of no effect.\n Interpretation by Sample Size \n\nn = 50: The distribution is wide and noisy. Zero is near the center, meaning we can’t confidently detect an effect.\nn = 200: The distribution begins to narrow. Zero is still well within the range of plausible outcomes.\nn = 500: The histogram becomes more concentrated. The true effect begins to emerge, and zero starts shifting toward the tails.\nn = 1000: The distribution is tightly centered. Zero lies in the tail, indicating that the true average difference is likely not zero.\n\n Conclusion \n\nAs sample size increases, the sampling distribution of the mean difference becomes narrower and more centered around the true population effect.\n\nThis exercise demonstrates: - The Law of Large Numbers: larger samples produce more stable estimates. - The power of simulation for understanding uncertainty and inference. - Why small samples often yield inconclusive or misleading results.\nThese plots reinforce that while we may see noisy or overlapping outcomes in small samples, with enough data, we get closer to the truth."
  },
  {
    "objectID": "a_b_test.html",
    "href": "a_b_test.html",
    "title": "Experimental Results",
    "section": "",
    "text": "import pandas as pd\n\n\ndf = pd.read_stata('karlan_list_2007.dta')\n\n\ndf.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\nfrom scipy import stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Separate data into treatment and control groups\ntreatment_group = df[df['treatment'] == 1]\ncontrol_group = df[df['control'] == 1]\n\n# T-test: mrm2 (months since last donation)\nttest_result = stats.ttest_ind(treatment_group['mrm2'].dropna(), control_group['mrm2'].dropna(), equal_var=False)\n\n# Linear regression: mrm2 ~ treatment\ndf_reg = df[['mrm2', 'treatment']].dropna()\nreg_result = smf.ols('mrm2 ~ treatment', data=df_reg).fit()\nttest_result, reg_result.summary()\n\n(TtestResult(statistic=0.11953155228177251, pvalue=0.9048549631450832, df=33394.47581389535),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   mrm2   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                 -0.000\n Method:                 Least Squares   F-statistic:                   0.01428\n Date:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\n Time:                        15:29:10   Log-Likelihood:            -1.9585e+05\n No. Observations:               50082   AIC:                         3.917e+05\n Df Residuals:                   50080   BIC:                         3.917e+05\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept     12.9981      0.094    138.979      0.000      12.815      13.181\n treatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n ==============================================================================\n Omnibus:                     8031.352   Durbin-Watson:                   2.004\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\n Skew:                           1.163   Prob(JB):                         0.00\n Kurtosis:                       3.751   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\n\nimport matplotlib.pyplot as plt\ngave_by_group = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ngave_by_group[\"group\"] = gave_by_group[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\nplt.figure(figsize=(6, 4))\nplt.bar(gave_by_group[\"group\"], gave_by_group[\"gave\"], width=0.5)\nplt.title(\"Proportion Who Donated by Group\")\nplt.ylabel(\"Proportion Gave\")\nplt.ylim(0, gave_by_group[\"gave\"].max() + 0.01)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\n\n# Re-import libraries and reload data due to kernel reset\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Ensure binary outcome is correctly typed\ndf['gave'] = df['gave'].astype(int)\n\n# T-test: response rate (gave) between treatment and control groups\ngave_treat = df[df['treatment'] == 1]['gave']\ngave_control = df[df['control'] == 1]['gave']\nt_stat, p_val = ttest_ind(gave_treat, gave_control, equal_var=False)\n\n# Regression: response as a function of treatment\nreg_gave = smf.ols('gave ~ treatment', data=df).fit()\n\nt_stat, p_val, reg_gave.summary()\n\n(3.2094621908279835,\n 0.0013309823450914173,\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\n Time:                        21:04:50   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\")\n\n\n\nimport statsmodels.api as sm\n\n# Prepare the variables\nX = sm.add_constant(df[\"treatment\"])\ny = df[\"gave\"]\n\n# Run the Probit regression\nprobit_model = sm.Probit(y, X)\nprobit_results = probit_model.fit()\n\nprobit_results.summary()\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\nProbit Regression Results\n\n\nDep. Variable:\ngave\nNo. Observations:\n50083\n\n\nModel:\nProbit\nDf Residuals:\n50081\n\n\nMethod:\nMLE\nDf Model:\n1\n\n\nDate:\nWed, 23 Apr 2025\nPseudo R-squ.:\n0.0009783\n\n\nTime:\n21:22:42\nLog-Likelihood:\n-5030.5\n\n\nconverged:\nTrue\nLL-Null:\n-5035.4\n\n\nCovariance Type:\nnonrobust\nLLR p-value:\n0.001696\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n-2.1001\n0.023\n-90.073\n0.000\n-2.146\n-2.054\n\n\ntreatment\n0.0868\n0.028\n3.113\n0.002\n0.032\n0.141\n\n\n\n\n\n\n# Subset the data for different match ratios\n# According to the dataset: ratio = '1', '2', '3' for 1:1, 2:1, 3:1\ndf_ratio = df[df[\"treatment\"] == 1].copy()\ndf_ratio[\"ratio\"] = df_ratio[\"ratio\"].astype(str)\n\n# Extract binary 'gave' for each match ratio group\ngave_1_1 = df_ratio[df_ratio[\"ratio\"] == \"1\"][\"gave\"]\ngave_2_1 = df_ratio[df_ratio[\"ratio\"] == \"2\"][\"gave\"]\ngave_3_1 = df_ratio[df_ratio[\"ratio\"] == \"3\"][\"gave\"]\n\n# Perform t-tests between match ratio groups\nttest_1_vs_2 = ttest_ind(gave_1_1, gave_2_1, equal_var=False)\nttest_1_vs_3 = ttest_ind(gave_1_1, gave_3_1, equal_var=False)\nttest_2_vs_3 = ttest_ind(gave_2_1, gave_3_1, equal_var=False)\n\nttest_1_vs_2, ttest_1_vs_3, ttest_2_vs_3\n\n(TtestResult(statistic=-0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836),\n TtestResult(statistic=-1.0150174470156275, pvalue=0.31010856527625774, df=22215.0529778684),\n TtestResult(statistic=-0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778))\n\n\n\n# Ensure 'gave' is binary\ndf['gave'] = df['gave'].astype(int)\n\n# Create dummy variables for each match ratio\n# This is only for treatment group, so filter and prepare accordingly\ndf_ratio = df[df['treatment'] == 1].copy()\ndf_ratio['ratio'] = df_ratio['ratio'].astype(str)\n\n# Create dummy variables: ratio1, ratio2, ratio3\ndf_ratio['ratio1'] = (df_ratio['ratio'] == '1').astype(int)\ndf_ratio['ratio2'] = (df_ratio['ratio'] == '2').astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == '3').astype(int)\n\n# Regression: gave ~ ratio1 + ratio2 + ratio3 (no intercept)\nimport statsmodels.api as sm\n\nX = df_ratio[['ratio1', 'ratio2', 'ratio3']]\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\n\nmodel.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ngave\nR-squared:\n0.000\n\n\nModel:\nOLS\nAdj. R-squared:\n-0.000\n\n\nMethod:\nLeast Squares\nF-statistic:\n0.6454\n\n\nDate:\nWed, 23 Apr 2025\nProb (F-statistic):\n0.524\n\n\nTime:\n21:40:37\nLog-Likelihood:\n16688.\n\n\nNo. Observations:\n33396\nAIC:\n-3.337e+04\n\n\nDf Residuals:\n33393\nBIC:\n-3.334e+04\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nratio1\n0.0207\n0.001\n14.912\n0.000\n0.018\n0.023\n\n\nratio2\n0.0226\n0.001\n16.267\n0.000\n0.020\n0.025\n\n\nratio3\n0.0227\n0.001\n16.335\n0.000\n0.020\n0.025\n\n\n\n\n\n\n\n\nOmnibus:\n38963.957\nDurbin-Watson:\n1.995\n\n\nProb(Omnibus):\n0.000\nJarque-Bera (JB):\n2506478.937\n\n\nSkew:\n6.511\nProb(JB):\n0.00\n\n\nKurtosis:\n43.394\nCond. No.\n1.00\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "hw1_questions.html#interpretation",
    "href": "hw1_questions.html#interpretation",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Interpretation",
    "text": "Interpretation\nWe assess balance between treatment and control groups using both statistical methods:\n\nT-Test:\n\nt = 0.120, p = 0.905\n\nResult: Not statistically significant\n\nRegression:\n\nCoefficient on treatment ≈ 0.014\n\np-value ≈ 0.905\n\n95% Confidence Interval: Includes zero\n\n\nThese results confirm no significant difference in mrm2 across groups, supporting the randomization mechanism. This aligns with Table 1 in Karlan & List (2007), where the group means were:\n\n\n\nGroup\nMean Months Since Last Donation\n\n\n\n\nTreatment\n13.012\n\n\nControl\n12.998"
  },
  {
    "objectID": "hw1_questions.html#charitable-contribution-made-1",
    "href": "hw1_questions.html#charitable-contribution-made-1",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Charitable Contribution Made",
    "text": "Charitable Contribution Made\nWe examine whether receiving a matching donation offer increases the likelihood of making a charitable donation. This is measured using the binary variable gave, which equals 1 if a donation was made and 0 otherwise.\nWe use both a t-test and a bivariate linear regression to assess the difference in response rate between treatment and control groups.\n Results Summary\n\n\n\n\n\n\n\n\n\nMethod\nEffect Size\np-value\nInterpretation\n\n\n\n\nT-Test\nt = 3.21\n0.0013\nStatistically significant\n\n\nRegression\n+0.0042 (0.42%)\n0.002\nStatistically significant\n\n\n\n\nControl group donation rate ≈ 1.79%\n\nTreatment group donation rate ≈ 2.21%\n\nThese values match the response rates reported in Table 2A, Panel A of Karlan & List (2007).\n Table 2A (Panel A): Response Rate Comparison\n\n\n\nGroup\nResponse Rate\nStd. Error\n\n\n\n\nControl\n0.018\n(0.001)\n\n\nTreatment\n0.022\n(0.001)\n\n\nMatch 1:1\n0.021\n(0.001)\n\n\nMatch 2:1\n0.023\n(0.001)\n\n\nMatch 3:1\n0.023\n(0.001)\n\n\n\n\nSource: Karlan & List (2007), Table 2A, Panel A\n\n Interpretation\nEven a small increase in the likelihood of giving — about 0.4 percentage points — is statistically significant in a large-scale field experiment with over 50,000 individuals.\nThis result shows that: - Matching donations have a causal impact on behavior. - People are more likely to respond to donation appeals when told their gift will be matched. - The psychological effect (e.g., feeling of leverage, social validation, urgency) may be as important as the financial incentive.\nThus, matched donations are an effective strategy not just in economics but in behavioral design for charitable fundraising.\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/hw1_questions.html",
    "href": "projects/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "projects/hw1_questions.html#introduction",
    "href": "projects/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse."
  },
  {
    "objectID": "projects/hw1_questions.html#data",
    "href": "projects/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nDataset Overview\nThe dataset contains over 50,000 observations from a field experiment in charitable giving. Variables include treatment assignments, donation behavior, match ratio conditions, prior giving history, and demographic information.\nBelow is a summary of key variable distributions and data structure.\n\nimport pandas as pd\ndf = pd.read_stata('karlan_list_2007.dta')\ndf.info()\ndf.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nWe tested whether the treatment and control groups differed in prior donor behavior by comparing the number of months since last donation (mrm2). Both a two-sample t-test (t = 0.120, p = 0.905) and a linear regression of mrm2 ~ treatment (β = 0.0137, p = 0.905) confirm no statistically significant difference. This supports the randomization mechanism and matches Table 1 in Karlan and List (2007).\n\nfrom scipy import stats\n\n# Clean data: drop NAs\ndf_clean = df[[\"mrm2\", \"treatment\", \"control\"]].dropna()\n\n# Split groups\ntreat = df_clean[df_clean['treatment'] == 1]['mrm2']\ncontrol = df_clean[df_clean['control'] == 1]['mrm2']\n\n# Perform Welch's t-test (no assumption of equal variances)\nttest = stats.ttest_ind(treat, control, equal_var=False)\n\n# Print results\nprint(f\"T-test result: t = {ttest.statistic:.3f}, p = {ttest.pvalue:.3f}\")\n\nimport statsmodels.formula.api as smf\n\n# Regression of mrm2 on treatment\nmodel = smf.ols(\"mrm2 ~ treatment\", data=df_clean).fit()\nmodel.summary()\n\n# Extract relevant results\nresults_table = pd.DataFrame({\n    'Variable': model.params.index,\n    'Coefficient': model.params.values,\n    'Std. Error': model.bse.values,\n    'p-value': model.pvalues.values,\n    '95% CI Lower': model.conf_int()[0].values,\n    '95% CI Upper': model.conf_int()[1].values\n})\n\n# Round for presentation\nresults_table = results_table.round(4)\nresults_table\n\nT-test result: t = 0.120, p = 0.905\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\nIntercept\n12.9981\n0.0935\n0.0000\n12.8148\n13.1815\n\n\n1\ntreatment\n0.0137\n0.1145\n0.9049\n-0.2108\n0.2382\n\n\n\n\n\n\n\n Interpretation \nWe assess balance between treatment and control groups using both statistical methods:\n\nT-Test:\n\nt = 0.120, p = 0.905\n\nResult: Not statistically significant\n\nRegression:\n\nCoefficient on treatment ≈ 0.014\n\np-value ≈ 0.905\n\n95% Confidence Interval: Includes zero\n\n\nThese results confirm no significant difference in mrm2 across groups, supporting the randomization mechanism. This aligns with Table 1 in Karlan & List (2007), where the group means were:\n\n\n\nGroup\nMean Months Since Last Donation\n\n\n\n\nTreatment\n13.012\n\n\nControl\n12.998"
  },
  {
    "objectID": "projects/hw1_questions.html#experimental-results",
    "href": "projects/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\ngave_by_group = df.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ngave_by_group[\"group\"] = gave_by_group[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\nplt.figure(figsize=(6, 4))\nplt.bar(gave_by_group[\"group\"], gave_by_group[\"gave\"], width=0.5)\nplt.title(\"Proportion Who Donated by Group\")\nplt.ylabel(\"Proportion Gave\")\nplt.ylim(0, gave_by_group[\"gave\"].max() + 0.01)\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nWe compare the response rate (i.e., whether a donation was made) between treatment and control groups.\nThe bar plot below shows that the treatment group, who received a matching grant offer, donated at a higher rate than the control group, who received a standard letter.\nThis visual confirms the core finding in Karlan & List (2007): matching donations increased participation in charitable giving.\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Ensure binary outcome is correctly typed\ndf['gave'] = df['gave'].astype(int)\n\n# T-test: response rate (gave) between treatment and control groups\ngave_treat = df[df['treatment'] == 1]['gave']\ngave_control = df[df['control'] == 1]['gave']\nt_stat, p_val = ttest_ind(gave_treat, gave_control, equal_var=False)\n\n# Display t-test result\nprint(f\"T-test result:\\nt = {t_stat:.3f}, p = {p_val:.4f}\\n\")\n\n# Regression: response as a function of treatment\nreg_gave = smf.ols('gave ~ treatment', data=df).fit()\n\nprint('Regression Results:')\n# Extract and format regression results\nresults_table = pd.DataFrame({\n    'Variable': reg_gave.params.index,\n    'Coefficient': reg_gave.params.values,\n    'Std. Error': reg_gave.bse.values,\n    'p-value': reg_gave.pvalues.values,\n    '95% CI Lower': reg_gave.conf_int()[0].values,\n    '95% CI Upper': reg_gave.conf_int()[1].values\n}).round(4)\n\nresults_table\n\nT-test result:\nt = 3.209, p = 0.0013\n\nRegression Results:\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\nIntercept\n0.0179\n0.0011\n0.0000\n0.0157\n0.0200\n\n\n1\ntreatment\n0.0042\n0.0013\n0.0019\n0.0015\n0.0068\n\n\n\n\n\n\n\n Charitable Contribution Made \nWe examine whether receiving a matching donation offer increases the likelihood of making a charitable donation. This is measured using the binary variable gave, which equals 1 if a donation was made and 0 otherwise.\nWe use both a t-test and a bivariate linear regression to assess the difference in response rate between treatment and control groups.\n Results Summary \n\n\n\n\n\n\n\n\n\nMethod\nEffect Size\np-value\nInterpretation\n\n\n\n\nT-Test\nt = 3.21\n0.0013\nStatistically significant\n\n\nRegression\n+0.0042 (0.42%)\n0.002\nStatistically significant\n\n\n\n\nControl group donation rate ≈ 1.79%\n\nTreatment group donation rate ≈ 2.21%\n\nThese values match the response rates reported in Table 2A, Panel A of Karlan & List (2007).\n Table 2A (Panel A): Response Rate Comparison \n\n\n\nGroup\nResponse Rate\nStd. Error\n\n\n\n\nControl\n0.018\n(0.001)\n\n\nTreatment\n0.022\n(0.001)\n\n\nMatch 1:1\n0.021\n(0.001)\n\n\nMatch 2:1\n0.023\n(0.001)\n\n\nMatch 3:1\n0.023\n(0.001)\n\n\n\n\nSource: Karlan & List (2007), Table 2A, Panel A\n\n Interpretation \nEven a small increase in the likelihood of giving — about 0.4 percentage points — is statistically significant in a large-scale field experiment with over 50,000 individuals.\nThis result shows that: - Matching donations have a causal impact on behavior. - People are more likely to respond to donation appeals when told their gift will be matched. - The psychological effect (e.g., feeling of leverage, social validation, urgency) may be as important as the financial incentive.\nThus, matched donations are an effective strategy not just in economics but in behavioral design for charitable fundraising.\n\nimport statsmodels.api as sm\n\n# Prepare the variables\nX = sm.add_constant(df[\"treatment\"])\ny = df[\"gave\"]\n\n# Run the Probit regression\nprobit_model = sm.Probit(y, X)\nprobit_results = probit_model.fit()\n\n# probit_results.summary()\n\n\n# Extract and format Probit results\nprobit_table = pd.DataFrame({\n    \"Variable\": probit_results.params.index,\n    \"Coefficient\": probit_results.params.values,\n    \"Std. Error\": probit_results.bse.values,\n    \"z-value\": probit_results.tvalues,\n    \"p-value\": probit_results.pvalues,\n    \"95% CI Lower\": probit_results.conf_int()[0],\n    \"95% CI Upper\": probit_results.conf_int()[1]\n}).round(4)\nprint(\"\\nProbit Results:\")\nprobit_table\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\nProbit Results:\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\nz-value\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\nconst\nconst\n-2.1001\n0.0233\n-90.0728\n0.0000\n-2.1458\n-2.0544\n\n\ntreatment\ntreatment\n0.0868\n0.0279\n3.1129\n0.0019\n0.0321\n0.1414\n\n\n\n\n\n\n\n Probit Regression: Impact of Matching Grant on Donation Likelihood \nTo replicate Table 3, Column (1) from Karlan & List (2007), we estimate a Probit model where the outcome is whether a donation was made (gave = 1) and the explanatory variable is assignment to treatment (treatment = 1).\n Our Probit Model Results \n\n\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\nz-value\np-value\n95% CI\n\n\n\n\nIntercept\n-2.100\n0.023\n-90.07\n&lt; 0.001\n[-2.146, -2.054]\n\n\nTreatment\n0.087\n0.028\n3.11\n0.002\n[0.032, 0.141]\n\n\n\n\nPseudo R²: 0.001\n\nObservations: 50,083\n\nThese results match the direction and significance of Table 3, Column (1) in the original study.\n Table 3: Primary Probit Regression Results from Karlan & List (2007) \n\n\n\n\n\n\n\n\n\nVariable\n(1) All\nStd. Err.\nSignificance\n\n\n\n\nTreatment\n0.004\n(0.001)\n***\n\n\nTreatment × 2:1 ratio\n0.002\n(0.002)\n\n\n\nTreatment × 3:1 ratio\n0.002\n(0.002)\n\n\n\nTreatment × $25,000 threshold\n-0.001\n(0.002)\n\n\n\nTreatment × $50,000 threshold\n0.000\n(0.002)\n\n\n\nTreatment × $100,000 threshold\n-0.000\n(0.002)\n\n\n\nTreatment × medium example amount\n0.001\n(0.002)\n\n\n\nTreatment × high example amount\n0.001\n(0.002)\n\n\n\nPseudo R²\n0.001\n\n\n\n\nObservations\n50,083\n\n\n\n\n\nNotes: - The paper reports marginal effects, whereas our Probit output gives latent index coefficients. - The magnitude of 0.004 in the paper corresponds to a marginal increase in probability of donating due to the treatment. - Our coefficient of 0.087 reflects the effect on the underlying propensity to give, which is standard in Probit estimation.\n Interpretation \nDespite a small effect size, the impact of being offered a matching donation is statistically significant. This suggests:\n\nEven subtle nudges, like framing a gift as matched by a leadership donor, can increase participation.\nThe result is economically meaningful due to the large sample size and real-world behavioral context.\n\nIn short: human generosity is sensitive to framing — and donors are more likely to act when they feel their gift has leverage.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Subset the data for different match ratios\n# According to the dataset: ratio = '1', '2', '3' for 1:1, 2:1, 3:1\ndf_ratio = df[df[\"treatment\"] == 1].copy()\ndf_ratio[\"ratio\"] = df_ratio[\"ratio\"].astype(str)\n\n# Extract binary 'gave' for each match ratio group\ngave_1_1 = df_ratio[df_ratio[\"ratio\"] == \"1\"][\"gave\"]\ngave_2_1 = df_ratio[df_ratio[\"ratio\"] == \"2\"][\"gave\"]\ngave_3_1 = df_ratio[df_ratio[\"ratio\"] == \"3\"][\"gave\"]\n\n# Perform t-tests between match ratio groups\nttest_1_vs_2 = ttest_ind(gave_1_1, gave_2_1, equal_var=False)\nttest_1_vs_3 = ttest_ind(gave_1_1, gave_3_1, equal_var=False)\nttest_2_vs_3 = ttest_ind(gave_2_1, gave_3_1, equal_var=False)\n\n# ttest_1_vs_2, ttest_1_vs_3, ttest_2_vs_3\n\n# Create clean results table\nt_test_results = pd.DataFrame({\n    \"Comparison\": [\"1:1 vs 2:1\", \"1:1 vs 3:1\", \"2:1 vs 3:1\"],\n    \"t-statistic\": [ttest_1_vs_2.statistic, ttest_1_vs_3.statistic, ttest_2_vs_3.statistic],\n    \"p-value\": [ttest_1_vs_2.pvalue, ttest_1_vs_3.pvalue, ttest_2_vs_3.pvalue]\n}).round(4)\nprint('t test Results:')\nt_test_results\n\nt test Results:\n\n\n\n\n\n\n\n\n\nComparison\nt-statistic\np-value\n\n\n\n\n0\n1:1 vs 2:1\n-0.9650\n0.3345\n\n\n1\n1:1 vs 3:1\n-1.0150\n0.3101\n\n\n2\n2:1 vs 3:1\n-0.0501\n0.9600\n\n\n\n\n\n\n\n Does Match Ratio Size Affect Donation Rates? \nWe investigate whether increasing the match ratio (from 1:1 to 2:1 to 3:1) has a statistically significant effect on the likelihood that someone donates.\nTo do this, we run a series of t-tests comparing donation rates (gave = 1) across match ratio groups, restricting the sample to individuals who received a matching offer.\n\n T-Test Results by Match Ratio \n\n\n\n\n\n\n\n\n\nComparison\nt-statistic\np-value\nInterpretation\n\n\n\n\n1:1 vs 2:1 match\n-0.965\n0.335\n❌ Not statistically significant\n\n\n1:1 vs 3:1 match\n-1.015\n0.310\n❌ Not statistically significant\n\n\n2:1 vs 3:1 match\n-0.050\n0.960\n❌ Not statistically significant\n\n\n\n Interpretation \nThese results show no significant difference in donation rates across the different match ratios. This means that:\n\nIncreasing the match multiplier from 1:1 to 2:1 or 3:1 does not lead to a higher likelihood of giving.\nThis supports the statement from Karlan & List (2007, p. 8):\n\n\n“The gift distributions across the various matching ratios are not significantly different from one another.”\n\nIn other words, people respond positively to the existence of a match, but not necessarily more when the match becomes more generous.\n Conclusion \nThe presence of a match appears to matter more than its magnitude. This suggests that:\n\nFraming and social cues — like simply saying “your gift will be matched” — may be more behaviorally powerful than the precise financial terms.\n\nThis insight is important for nonprofit fundraisers: focus on highlighting the match rather than inflating the ratio.\n\n# Ensure 'gave' is binary\ndf['gave'] = df['gave'].astype(int)\n\n# Create dummy variables for each match ratio\n# This is only for treatment group, so filter and prepare accordingly\ndf_ratio = df[df['treatment'] == 1].copy()\ndf_ratio['ratio'] = df_ratio['ratio'].astype(str)\n\n# Create dummy variables: ratio1, ratio2, ratio3\ndf_ratio['ratio1'] = (df_ratio['ratio'] == '1').astype(int)\ndf_ratio['ratio2'] = (df_ratio['ratio'] == '2').astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == '3').astype(int)\n\n# Regression: gave ~ ratio1 + ratio2 + ratio3 (no intercept)\nimport statsmodels.api as sm\n\nX = df_ratio[['ratio1', 'ratio2', 'ratio3']]\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\n\n# model.summary()\n\n\n# Format regression output\nratio_reg_table = pd.DataFrame({\n    \"Match Ratio\": [\"1:1\", \"2:1\", \"3:1\"],\n    \"Coefficient\": model.params.values,\n    \"Std. Error\": model.bse.values,\n    \"p-value\": model.pvalues.values,\n    \"95% CI Lower\": model.conf_int()[0].values,\n    \"95% CI Upper\": model.conf_int()[1].values\n}).round(4)\n\nprint('Reression Results:')\nratio_reg_table\n\nReression Results:\n\n\n\n\n\n\n\n\n\nMatch Ratio\nCoefficient\nStd. Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n1:1\n0.0207\n0.0014\n0.0\n0.0180\n0.0235\n\n\n1\n2:1\n0.0226\n0.0014\n0.0\n0.0199\n0.0254\n\n\n2\n3:1\n0.0227\n0.0014\n0.0\n0.0200\n0.0255\n\n\n\n\n\n\n\n Behavioral Insight: Why Match Size Doesn’t Matter (Much) \nThis regression shows that all forms of match ratios — 1:1, 2:1, and 3:1 — significantly increase the likelihood that someone donates, with donation rates clustering around 2%.\nHowever, the differences between match sizes are extremely small:\n\nPeople who saw a 1:1 match donated at a rate of 2.07%.\nThose who saw a 2:1 match gave at 2.26%.\nWith a 3:1 match, the rate was 2.27%.\n\nThese results suggest that once a match is present, increasing its generosity has little additional impact. In other words:\n\nIt’s the existence of the match that matters, not its size.\n\nThis behavior aligns with theories in behavioral economics: - The match acts as a signal of social proof or endorsement. - It may create a sense of urgency or leverage (“my donation matters more”). - But donors aren’t particularly sensitive to how generous the match is — at least not in terms of deciding whether or not to give.\n Implication for Fundraising \nFrom a practical standpoint, this means that: - Fundraisers don’t need to offer high match ratios to see results. - A simple, clearly communicated 1:1 match may be just as effective as a 3:1 match in increasing participation.\nThis finding reinforces the power of framing and perception in influencing human behavior.\n\n# Compute the actual mean response (gave) for each ratio group directly from the data\nmean_1_1 = df_ratio[df_ratio[\"ratio\"] == \"1\"][\"gave\"].mean()\nmean_2_1 = df_ratio[df_ratio[\"ratio\"] == \"2\"][\"gave\"].mean()\nmean_3_1 = df_ratio[df_ratio[\"ratio\"] == \"3\"][\"gave\"].mean()\n\n# Calculate differences in response rates\ndiff_2_1_vs_1_1 = mean_2_1 - mean_1_1\ndiff_3_1_vs_2_1 = mean_3_1 - mean_2_1\n\n# Extract coefficients from regression model\ncoef_1_1 = model.params[\"ratio1\"]\ncoef_2_1 = model.params[\"ratio2\"]\ncoef_3_1 = model.params[\"ratio3\"]\n\n# Calculate differences in coefficients\ncoef_diff_2_1_vs_1_1 = coef_2_1 - coef_1_1\ncoef_diff_3_1_vs_2_1 = coef_3_1 - coef_2_1\n\n# (mean_1_1, mean_2_1, mean_3_1,\n#  diff_2_1_vs_1_1, diff_3_1_vs_2_1,\n#  coef_diff_2_1_vs_1_1, coef_diff_3_1_vs_2_1)\n\n\n# Organize values into a formatted summary table\ncomparison_table = pd.DataFrame({\n    \"Comparison\": [\"2:1 vs 1:1\", \"3:1 vs 2:1\"],\n    \"Diff (means)\": [diff_2_1_vs_1_1, diff_3_1_vs_2_1],\n    \"Diff (regression coefficients)\": [coef_diff_2_1_vs_1_1, coef_diff_3_1_vs_2_1]\n}).round(5)\nprint('Results:')\ncomparison_table\n\nResults:\n\n\n\n\n\n\n\n\n\nComparison\nDiff (means)\nDiff (regression coefficients)\n\n\n\n\n0\n2:1 vs 1:1\n0.00188\n0.00188\n\n\n1\n3:1 vs 2:1\n0.00010\n0.00010\n\n\n\n\n\n\n\n Comparing Response Rates Across Match Ratios \nWe examine how the size of the match (1:1 vs. 2:1 vs. 3:1) influences the probability that an individual makes a donation. We do this in two ways:\n\nDirectly from the data by calculating average donation rates within each match group.\nFrom the fitted coefficients of a regression on dummy variables for each ratio.\n\n\n Response Rate Differences \n\n\n\n\n\n\n\n\nComparison\nDirect from Data\nFrom Regression Coefficients\n\n\n\n\n2:1 vs 1:1 match\n0.00188 (0.19%)\n0.00188 (0.19%)\n\n\n3:1 vs 2:1 match\n0.00010 (0.01%)\n0.00010 (0.01%)\n\n\n\n\nThese differences represent increases in the probability of donating when moving from one match ratio to a higher one.\nThe results are identical across both methods, which supports the robustness of the findings.\n\n Interpretation \n\nMoving from a 1:1 to 2:1 match slightly increases donation rates by about 0.19 percentage points.\nIncreasing from a 2:1 to a 3:1 match has a negligible effect — only 0.01 percentage points.\nThese differences are statistically very small and are unlikely to be meaningful in practice.\n\n Conclusion \nOur analysis shows that:\n\nOnce a match is introduced, increasing the match ratio does not meaningfully increase the likelihood of giving.\n\nThis confirms the finding from Karlan & List (2007):\n\n“The gift distributions across the various matching ratios are not significantly different from one another.”\n\nIn short, it’s the presence of a match offer — not its generosity — that influences donor behavior.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Run a t-test on the amount given between treatment and control groups\namount_treat = df[df['treatment'] == 1]['amount']\namount_control = df[df['control'] == 1]['amount']\namount_ttest = ttest_ind(amount_treat, amount_control, equal_var=False)\n\n# Run a bivariate linear regression: amount ~ treatment\namount_reg = smf.ols('amount ~ treatment', data=df).fit()\n\n# amount_ttest.statistic, amount_ttest.pvalue, amount_reg.summary()\n\n# Format regression output into a clean table\namount_table = pd.DataFrame({\n    \"Variable\": amount_reg.params.index,\n    \"Coefficient\": amount_reg.params.values,\n    \"Std. Error\": amount_reg.bse.values,\n    \"p-value\": amount_reg.pvalues.values,\n    \"95% CI Lower\": amount_reg.conf_int()[0].values,\n    \"95% CI Upper\": amount_reg.conf_int()[1].values\n}).round(4)\n\namount_table\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\nIntercept\n0.8133\n0.0674\n0.0000\n0.6811\n0.9454\n\n\n1\ntreatment\n0.1536\n0.0826\n0.0628\n-0.0082\n0.3154\n\n\n\n\n\n\n\n Size of Charitable Contribution \nWe tested whether receiving a matching donation offer affects the amount donated using a t-test and linear regression:\n Results \n\n\n\n\n\n\n\n\n\nMethod\nTreatment Effect\np-value\nConclusion\n\n\n\n\nT-Test\n+$0.15\n0.055\n🔸 Marginally not significant\n\n\nRegression\n+$0.15\n0.063\n🔸 Suggestive but inconclusive\n\n\n\n\nControl group average: ~$0.81\n\nTreatment group average: ~$0.96\n\n Interpretation \n\nThe treatment group gave slightly more, but the difference is not statistically significant at the 5% level.\nThis suggests that while match offers increase participation, they have a much smaller effect on how much people give.\n\n Takeaway \n\nMatching donations may encourage more people to give, but do not substantially increase donation size.\n\n\n# Limit the data to only those who made a donation (amount &gt; 0)\ndf_positive = df[df['amount'] &gt; 0].copy()\n\n# T-test for amount among donors only\namount_treat_pos = df_positive[df_positive['treatment'] == 1]['amount']\namount_control_pos = df_positive[df_positive['control'] == 1]['amount']\namount_ttest_pos = ttest_ind(amount_treat_pos, amount_control_pos, equal_var=False)\n\n# Regression: amount ~ treatment (for donors only)\namount_reg_pos = smf.ols('amount ~ treatment', data=df_positive).fit()\n\n# amount_ttest_pos.statistic, amount_ttest_pos.pvalue, amount_reg_pos.summary()\n\n\n# Clean regression summary\namount_conditional_table = pd.DataFrame({\n    \"Variable\": amount_reg_pos.params.index,\n    \"Coefficient\": amount_reg_pos.params.values,\n    \"Std. Error\": amount_reg_pos.bse.values,\n    \"p-value\": amount_reg_pos.pvalues.values,\n    \"95% CI Lower\": amount_reg_pos.conf_int()[0].values,\n    \"95% CI Upper\": amount_reg_pos.conf_int()[1].values\n}).round(4)\n\namount_conditional_table\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\nIntercept\n45.5403\n2.4234\n0.0000\n40.7850\n50.2956\n\n\n1\ntreatment\n-1.6684\n2.8724\n0.5615\n-7.3048\n3.9680\n\n\n\n\n\n\n\n Conditional Donation Amount: Among Donors Only \nTo isolate the effect of treatment on the amount given, we restrict the sample to only those individuals who made a donation (amount &gt; 0).\nWe use both a t-test and a bivariate regression (amount ~ treatment) to compare average donation sizes between treatment and control groups.\n Results Summary \n\n\n\n\n\n\n\n\n\nMethod\nTreatment Effect\np-value\nConclusion\n\n\n\n\nT-Test (donors only)\nt = -0.58\n0.559\n❌ Not statistically significant\n\n\nRegression\n-$1.67\n0.561\n❌ Not statistically significant\n\n\n\n\nControl group average donation: ~$45.54\n\nTreatment group average donation: ~$43.87\n\n Interpretation \n\nThe treatment group donated slightly less on average, but the difference is not statistically meaningful.\nThis suggests that while the match offer encourages more people to donate, it does not increase donation size among those who would give anyway.\nBecause we only include those who donated, the treatment effect here is not causal — it’s conditional and may suffer from selection bias.\n\n Conclusion \n\nMatched donations are effective at increasing the number of donors, but not the amount donated by each donor — at least among those who already choose to give.\n\n\nimport matplotlib.pyplot as plt\n\n# Filter to donors only\ndf_donors = df[df[\"amount\"] &gt; 0]\n\n# Separate treatment and control donors\ntreat_donors = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\ncontrol_donors = df_donors[df_donors[\"control\"] == 1][\"amount\"]\n\n# Calculate means\nmean_treat = treat_donors.mean()\nmean_control = control_donors.mean()\n\n# Create side-by-side histograms\nfig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n\n# Control group plot\naxes[0].hist(control_donors, bins=30, color=\"skyblue\", edgecolor=\"black\")\naxes[0].axvline(mean_control, color=\"red\", linestyle=\"--\", label=f\"Mean = ${mean_control:.2f}\")\naxes[0].set_title(\"Control Group Donations\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].legend()\n\n# Treatment group plot\naxes[1].hist(treat_donors, bins=30, color=\"lightgreen\", edgecolor=\"black\")\naxes[1].axvline(mean_treat, color=\"red\", linestyle=\"--\", label=f\"Mean = ${mean_treat:.2f}\")\naxes[1].set_title(\"Treatment Group Donations\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n Distribution of Donation Amounts Among Donors \nWe now focus on individuals who actually made a donation (amount &gt; 0) to analyze how much they gave, and whether the treatment group (those offered a matching donation) gave more than the control group.\nWe visualize the distribution of donation amounts with two histograms — one for each group — and include a red dashed line indicating the average donation in each.\n Interpretation \n\nBoth distributions are heavily right-skewed, which is common in charitable giving: most donors give modest amounts, but a few give significantly more.\nThe average donation in the control group was about $45.54, while the treatment group averaged $43.87.\nThis difference is not statistically significant, as confirmed by both a t-test and a regression limited to donors.\n\n What Did We Learn? \n\nWhile the matching donation offer increases the probability of donating, it does not increase the donation amount among those who choose to give.\nIn fact, the average donation in the treatment group is slightly lower, though the difference is not meaningful.\n\n Important Caveat \nThis analysis is based only on people who gave, so the treatment coefficient does not have a causal interpretation here. This subset is not randomly assigned — it’s a selected group, which may differ systematically between treatment and control.\n Fundraising Implication \n\nMatching offers are powerful tools to increase participation, but they do not necessarily lead to larger individual gifts.\n\nTo increase average donation size, fundraisers may need additional tactics — such as suggested donation levels, tiered match thresholds, or social proof."
  },
  {
    "objectID": "projects/hw1_questions.html#simulation-experiment",
    "href": "projects/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Extract donation amounts for control and treatment\ncontrol_data = df[df[\"control\"] == 1][\"amount\"]\ntreatment_data = df[df[\"treatment\"] == 1][\"amount\"]\n\n# Simulate draws from each distribution\nnp.random.seed(42)\nsim_control = np.random.choice(control_data, size=100_000, replace=True)\nsim_treatment = np.random.choice(treatment_data, size=10_000, replace=True)\n\n# Calculate 10,000 differences between treatment and control draws\nsim_control_subset = np.random.choice(sim_control, size=10_000, replace=False)\ndiffs = sim_treatment - sim_control_subset\n\n# Compute cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Average Difference\")\nplt.axhline(y=np.mean(treatment_data) - np.mean(control_data), color=\"red\", linestyle=\"--\", label=\"True Mean Difference\")\nplt.title(\"Cumulative Average of Treatment-Control Differences\")\nplt.xlabel(\"Number of Draws\")\nplt.ylabel(\"Cumulative Average Difference in Donation Amount\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n Simulated Cumulative Average Differences \nTo better understand the behavior of sample averages and connect to the concepts from our first class (Slide 43), we simulate the cumulative effect of donation differences between the treatment and control groups.\n Simulation Setup \n\nWe simulate 100,000 random draws from the control group donation distribution.\nWe simulate 10,000 random draws from the treatment group.\nFor each of the 10,000 pairs, we calculate the difference: treatment - control.\nWe then compute the cumulative average of these 10,000 differences.\n\n Plot Interpretation \nThe plot below shows:\n\nA blue line representing the cumulative average of the simulated differences.\nA red dashed line indicating the true difference in means between treatment and control groups (calculated from the full dataset).\n\nAs the number of draws increases, the cumulative average approaches the true difference.\nThis illustrates the Law of Large Numbers: with enough data, sample-based estimates converge to the population value.\n What We Learnt \n\nThis simulation confirms that even in noisy, skewed data like donations, repeated sampling yields reliable estimates.\n\nIt also demonstrates that the difference in means we compute from data is not just a fluke — it’s what we’d expect if we sampled repeatedly from the same distributions.\n\n\nCentral Limit Theorem\n\n# Define a function to simulate mean differences for a given sample size\ndef simulate_differences(sample_size, n_reps=1000):\n    differences = []\n    for _ in range(n_reps):\n        sample_control = np.random.choice(control_data, size=sample_size, replace=True)\n        sample_treatment = np.random.choice(treatment_data, size=sample_size, replace=True)\n        differences.append(np.mean(sample_treatment) - np.mean(sample_control))\n    return differences\n\n# Simulate for each sample size\nnp.random.seed(42)\nsizes = [50, 200, 500, 1000]\nsimulated_results = {size: simulate_differences(size) for size in sizes}\n\n# Plot histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, size in enumerate(sizes):\n    axes[i].hist(simulated_results[size], bins=30, color='lightgray', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='--', label=\"Zero\")\n    axes[i].set_title(f\"Sample Size = {size}\")\n    axes[i].set_xlabel(\"Mean Difference (Treatment - Control)\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n Sampling Distributions at Different Sample Sizes \nTo mirror the exercise from Slide 44 of our first class, we simulate the sampling distribution of the mean difference in donation amount between the treatment and control groups.\nFor each of four different sample sizes — 50, 200, 500, and 1000 — we:\n\nDraw n observations from each group.\nCompute the difference in mean donation: treatment - control.\nRepeat the process 1,000 times.\nPlot the histogram of those 1,000 average differences.\n\n Histograms of Simulated Mean Differences \nEach plot includes a red dashed line at zero, representing the null hypothesis of no effect.\n Interpretation by Sample Size \n\nn = 50: The distribution is wide and noisy. Zero is near the center, meaning we can’t confidently detect an effect.\nn = 200: The distribution begins to narrow. Zero is still well within the range of plausible outcomes.\nn = 500: The histogram becomes more concentrated. The true effect begins to emerge, and zero starts shifting toward the tails.\nn = 1000: The distribution is tightly centered. Zero lies in the tail, indicating that the true average difference is likely not zero.\n\n Conclusion \n\nAs sample size increases, the sampling distribution of the mean difference becomes narrower and more centered around the true population effect.\n\nThis exercise demonstrates: - The Law of Large Numbers: larger samples produce more stable estimates. - The power of simulation for understanding uncertainty and inference. - Why small samples often yield inconclusive or misleading results.\nThese plots reinforce that while we may see noisy or overlapping outcomes in small samples, with enough data, we get closer to the truth."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nNujoum Unus\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/hw1_questions.html#purpose-of-the-study",
    "href": "projects/hw1_questions.html#purpose-of-the-study",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Purpose of the Study",
    "text": "Purpose of the Study\nKarlan and List aimed to answer a simple but important question:\n&gt; Do people give more when their donation is matched? And if so, does the size of the match matter?\nThey also explored additional behavioral levers commonly used in fundraising, such as challenge framing, suggested donation amounts, and goal-based appeals."
  },
  {
    "objectID": "projects/hw1_questions.html#project-overview",
    "href": "projects/hw1_questions.html#project-overview",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Project Overview",
    "text": "Project Overview\nIn this replication study, we use the same dataset provided by Karlan and List to:\n\nReproduce their key findings\nValidate the statistical robustness of their claims\nExplore new visualizations and simulations that illuminate the behavioral mechanisms at play\nReflect on what this experiment teaches us about human motivation, social framing, and economic incentives in the context of public goods\n\nThis report follows a structured analysis of donation likelihood, donation size, and how different dimensions of the match offer (ratio, threshold, framing) influence both."
  },
  {
    "objectID": "projects/hw1_questions.html#experimental-design",
    "href": "projects/hw1_questions.html#experimental-design",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Design",
    "text": "Experimental Design\nThe letters fell into three broad treatment types:\n\nStandard Fundraising Letter (Control)\n\nA typical letter requesting support for the organization, with no additional incentives or matching language.\n\nMatching Grant Letter\n\nIncluded a paragraph stating that a leadership donor would match any contribution at one of three possible ratios:\n\n1:1 (every dollar given is doubled)\n\n2:1 (every dollar is tripled)\n\n3:1 (every dollar quadrupled)\n\n\nMatching offers also varied by threshold, i.e., the maximum amount the leadership donor would match:\n\n$25,000, $50,000, $100,000, or unstated.\n\nSuggested donation levels were tailored based on each recipient’s previous giving history:\n\nTheir highest previous gift\n\n1.25× their highest gift\n\n1.5× their highest gift\n\n\nChallenge Grant Letter\n\nFramed the offer as part of a collective effort or campaign challenge, appealing to urgency and social impact rather than pure match mechanics.\n\n\nBecause each component (match ratio, threshold, suggested donation amount) was randomized independently within the matching grant group, the experiment had a factorial design — allowing the researchers to isolate and measure the effects of each variable."
  },
  {
    "objectID": "projects/hw1_questions.html#why-this-matters",
    "href": "projects/hw1_questions.html#why-this-matters",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Why This Matters",
    "text": "Why This Matters\nAt the time of the study, fundraisers often relied on rules of thumb and anecdotes, lacking hard data on what actually drives giving. Karlan and List’s approach brought scientific rigor to the domain of nonprofit fundraising by:\n\nLeveraging random assignment to establish causality\nTesting commonly used marketing strategies under real-world conditions\nGenerating insights with practical implications for organizations seeking to raise more money"
  },
  {
    "objectID": "projects/hw1_questions.html#contribution-to-the-literature",
    "href": "projects/hw1_questions.html#contribution-to-the-literature",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Contribution to the Literature",
    "text": "Contribution to the Literature\nThis study represents one of the first large-scale natural field experiments in charitable giving. It moved beyond lab settings and survey experiments to observe real decisions involving real money. The results helped bridge the gap between behavioral economics and fundraising practice, offering evidence-backed recommendations on:\n\nThe efficacy of matching offers\n\nHow much match ratios influence behavior\n\nWhether people respond to thresholds or suggested amounts\n\nThe heterogeneous effects by donor characteristics and geography"
  },
  {
    "objectID": "projects/hw1_questions.html#background",
    "href": "projects/hw1_questions.html#background",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Background",
    "text": "Background\nCharitable organizations often rely on fundraising letters to solicit donations, but little rigorous evidence has been available to guide how those letters should be designed. In a groundbreaking field experiment, economists Dean Karlan and John List set out to test how different framing strategies and financial incentives affect individual donation behavior.\nThe experiment, conducted in collaboration with a politically-oriented nonprofit organization, involved mailing 50,083 fundraising letters to previous donors. Crucially, the recipients were randomly assigned to different treatment groups, allowing the researchers to measure causal effects rather than mere correlations."
  }
]